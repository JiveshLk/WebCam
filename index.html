<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Camera App with Shader</title>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            height: 100%;
            overflow: hidden; /* Prevent scrolling */
        }
        #video-container {
            width: 100%;
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: #f0f0f0;
            position: relative;
        }
        canvas {
            width: 100%;
            height: 100%;
            object-fit: contain; /* Ensures canvas fills the screen */
        }
    </style>
</head>
<body>
    <div id="video-container">
        <canvas id="glcanvas"></canvas>
    </div>
    <div id="debug-info" style="position: absolute; top: 0; left: 0; color: white; background: rgba(0,0,0,0.5); padding: 10px;"></div>

    <script>
        const canvas = document.getElementById('glcanvas');
        const gl = canvas.getContext('webgl');
        let video;

        if (!gl) {
            alert('Unable to initialize WebGL. Your browser may not support it.');
            throw new Error('WebGL not supported');
        }

        // Vertex shader program
        const vsSource = `
            attribute vec4 vertexPosition;
            attribute vec2 textureCoord;
            varying highp vec2 vTextureCoord;
            void main(void) {
                gl_Position = vertexPosition;
                vTextureCoord = textureCoord;
            }
        `;

        const fsSource = `
            precision mediump float;
            varying mediump vec2 vTextureCoord;
            uniform sampler2D uSampler;
            uniform vec2 uResolution;

            void main(void) {
                vec2 uv = vTextureCoord;
                vec3 baseColor = texture2D(uSampler, uv).rgb;

                // Calculate the blur radius as a fraction of the canvas width
                // Here, the blur effect is scaled relative to a reference resolution (e.g., 1280 pixels wide)
                float referenceWidth = 1280.0;
                float blurScale = uResolution.x / referenceWidth;
                float blurRadius = (2.0 / uResolution.x) * blurScale;

                // Parameters for the blur effect, potentially adjusted for responsiveness
                float sigmaColor = 0.1;
                float sigmaSpace = 0.015 * blurScale; // Adjust sigmaSpace to scale with resolution

                vec3 filteredColor = vec3(0.0);
                float weightSum = 0.0;

                // Loop over surrounding pixels within the blur radius
                for (int x = -2; x <= 2; x++) {
                    for (int y = -2; y <= 2; y++) {
                        vec2 offset = vec2(float(x), float(y)) * blurRadius;
                        vec3 sampleColor = texture2D(uSampler, uv + offset).rgb;

                        float colorDistance = distance(sampleColor, baseColor);
                        float weightColor = exp(-(colorDistance * colorDistance) / (2.0 * sigmaColor * sigmaColor));

                        float spatialDistance = length(offset);
                        float weightSpace = exp(-(spatialDistance * spatialDistance) / (2.0 * sigmaSpace * sigmaSpace));

                        float weight = weightColor * weightSpace;
                        filteredColor += sampleColor * weight;
                        weightSum += weight;
                    }
                }

                filteredColor /= weightSum;

                gl_FragColor = vec4(filteredColor, 1.0);
            }
        `;


        async function getCameraStream() {
            try {
                const constraints = { video: { facingMode: "user", width: { ideal: 1280, max: 1280 }, height: { ideal: 1280, max: 1280 } } };
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                video = document.createElement('video');
                video.srcObject = stream;
                video.play();
                video.onloadedmetadata = function() {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    initWebGL(video);
                    updateDebugInfo();
                };
                
            } catch (error) {
                console.error('Error accessing camera:', error);
            }
        }

        function initWebGL(video) {
            const shaderProgram = initShaderProgram(gl, vsSource, fsSource);
            const buffers = initBuffers(gl);
            const texture = initTexture(gl, video);
            const programInfo = {
                program: shaderProgram,
                attribLocations: {
                    vertexPosition: gl.getAttribLocation(shaderProgram, 'vertexPosition'),
                    textureCoord: gl.getAttribLocation(shaderProgram, 'textureCoord'),
                },
                uniformLocations: {
                    uSampler: gl.getUniformLocation(shaderProgram, 'uSampler'),
                    uResolution: gl.getUniformLocation(shaderProgram, 'uResolution'),
                },
            };

            function render() {
                drawScene(gl, programInfo, buffers, texture, video);
                requestAnimationFrame(render);
            }
            requestAnimationFrame(render);
        }

        function updateDebugInfo() {
            const debugInfo = document.getElementById('debug-info');
            debugInfo.textContent = `Canvas Width: ${canvas.width}px, Canvas Height: ${canvas.height}px`;
        }

        function initShaderProgram(gl, vsSource, fsSource) {
            const vertexShader = loadShader(gl, gl.VERTEX_SHADER, vsSource);
            const fragmentShader = loadShader(gl, gl.FRAGMENT_SHADER, fsSource);

            const shaderProgram = gl.createProgram();
            gl.attachShader(shaderProgram, vertexShader);
            gl.attachShader(shaderProgram, fragmentShader);
            gl.linkProgram(shaderProgram);

            if (!gl.getProgramParameter(shaderProgram, gl.LINK_STATUS)) {
                alert('Unable to initialize the shader program: ' + gl.getProgramInfoLog(shaderProgram));
                return null;
            }
            return shaderProgram;
        }
        function loadShader(gl, type, source) {
            const shader = gl.createShader(type);
            gl.shaderSource(shader, source);
            gl.compileShader(shader);
            if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                alert('An error occurred compiling the shaders: ' + gl.getShaderInfoLog(shader));
                gl.deleteShader(shader);
                return null;
            }
            return shader;
        }

        function initBuffers(gl) {
            const positionBuffer = gl.createBuffer();
            gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
            const positions = [
                -1.0,  1.0,
                 1.0,  1.0,
                -1.0, -1.0,
                 1.0, -1.0,
            ];
            gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(positions), gl.STATIC_DRAW);

            const textureCoordBuffer = gl.createBuffer();
            gl.bindBuffer(gl.ARRAY_BUFFER, textureCoordBuffer);
            const textureCoordinates = [
                1.0, 0.0, // Flip the texture horizontally
                0.0, 0.0, // Flip the texture horizontally
                1.0, 1.0, // Flip the texture horizontally
                0.0, 1.0, // Flip the texture horizontally
            ];

            gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(textureCoordinates), gl.STATIC_DRAW);

            return {
                position: positionBuffer,
                textureCoord: textureCoordBuffer,
            };
        }

        function initTexture(gl, video) {
            const texture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, texture);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);

            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, 1, 1, 0, gl.RGBA, gl.UNSIGNED_BYTE, new Uint8Array([0, 0, 0, 255]));

            return texture;
        }

        function drawScene(gl, programInfo, buffers, texture, video) {
            gl.viewport(0, 0, canvas.width, canvas.height);
            gl.clearColor(0.0, 0.0, 0.0, 1.0);
            gl.clear(gl.COLOR_BUFFER_BIT);

            gl.useProgram(programInfo.program);
            gl.uniform2f(programInfo.uniformLocations.uResolution, canvas.width, canvas.height); // Set the resolution uniform

            // Bind the position buffer.
            gl.bindBuffer(gl.ARRAY_BUFFER, buffers.position);
            gl.vertexAttribPointer(programInfo.attribLocations.vertexPosition, 2, gl.FLOAT, false, 0, 0);
            gl.enableVertexAttribArray(programInfo.attribLocations.vertexPosition);

            // Bind the texture coordinate buffer.
            gl.bindBuffer(gl.ARRAY_BUFFER, buffers.textureCoord);
            gl.vertexAttribPointer(programInfo.attribLocations.textureCoord, 2, gl.FLOAT, false, 0, 0);
            gl.enableVertexAttribArray(programInfo.attribLocations.textureCoord);

            // Specify the texture to map onto the faces.
            gl.activeTexture(gl.TEXTURE0);
            gl.bindTexture(gl.TEXTURE_2D, texture);
            gl.uniform1i(programInfo.uniformLocations.uSampler, 0);

            // Update the video texture for each frame.
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, video);

            // Draw the rectangle.
            gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
        }


        getCameraStream();
    </script>
</body>
</html>
